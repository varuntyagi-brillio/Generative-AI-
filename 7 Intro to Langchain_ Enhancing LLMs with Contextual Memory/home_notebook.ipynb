{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/Documents/MS/GenAI/venv_gen/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = \"2023-03-15-preview\",\n",
    "    temperature = 0.2, \n",
    "    model = \"gpt-4o-mini\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola! Claro, estaré encantado de ayudarte. ¿En qué necesitas ayuda?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\",\"You're a helpful assistant that tranlates English to Spanish.\"),\n",
    "    (\"user\",\"Hello ! Can you please help me, I'm new here !\")\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatTogether(client=<openai.resources.chat.completions.Completions object at 0x76b62836cb80>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x76b61037d8a0>, model_name='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', temperature=0.2, openai_api_key=SecretStr('**********'), max_tokens=200, together_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Together AI\n",
    "from langchain_together import ChatTogether\n",
    "\n",
    "llm = ChatTogether(\n",
    "    api_key=os.getenv(\"TOGETHER_API_KEY\"),\n",
    "    temperature= 0.2,\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bonjour ! Bien sûr, je suis là pour vous aider ! Comment puis-je vous aider aujourd'hui ? (Hello! Of course, I'm here to help! How can I assist you today?)\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You're a helpful assistant that tranlates English to French.\"),\n",
    "    (\"human\", \"Hello ! Can you please help me, I'm new here !\")\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "\n",
    "#define the promt template\n",
    "product_description_template = PromptTemplate(\n",
    "    input_variable = [\"product_name\", \"product_features\"],\n",
    "    template = ''' \n",
    "    You are a creative copywriter. Write an engaging product description for the following product:\n",
    "\n",
    "    Product Name: {product_name}\n",
    "    Features: {product_features}\n",
    "\n",
    "    The description should be catchy and highlight the unique selling points of the product.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_product_derc(product_name, product_feature):\n",
    "    \n",
    "    chain = LLMChain(\n",
    "        llm = llm, \n",
    "        prompt = product_description_template\n",
    "        )\n",
    "    \n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"product_name\": product_name,\n",
    "            \"product_features\" :product_feature\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product_name': 'Smart Home Design',\n",
       " 'product_features': 'Voice control, AI-powered, Energy efficient, Multi-room support',\n",
       " 'text': \"**Introducing Smart Home Design: Where Innovation Meets Elegance**\\n\\nImagine a home that adapts to your every need, where the lights dim to perfection as you settle in for a movie night, and the thermostat adjusts to your preferred temperature without you even lifting a finger. Welcome to the future of home living with Smart Home Design.\\n\\nThis revolutionary system is not just a smart home device - it's a personal assistant, a energy manager, and a design expert all in one. With voice control at your fingertips (or rather, your voice), you can effortlessly manage your home's ambiance, security, and energy efficiency.\\n\\n**The Power of AI**\\n\\nOur AI-powered technology learns your habits and preferences, anticipating your needs and adjusting the settings accordingly. Want to wake up to a bright and cheerful morning? Smart Home Design will have the lights on and the coffee brewing, just the way you like it.\\n\\n**Effortless Energy Efficiency**\\n\\nSay goodbye to wasted energy and hello to significant savings with our\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name = \"Smart Home Design\"\n",
    "product_feature = \"Voice control, AI-powered, Energy efficient, Multi-room support\"\n",
    "\n",
    "generate_product_derc(product_name, product_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain Prompt Template\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "'''\n",
    "Translate the following review to English.\n",
    "{Review}\n",
    "'''\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=llm,\n",
    "                     prompt = first_prompt,\n",
    "                     output_key = \"English_Review\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, \n",
    "                     prompt=second_prompt,\n",
    "                     output_key=\"summary\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review, answer with just the name of the language:\\n\\n{Review}\"\n",
    ")\n",
    "\n",
    "chain_three = LLMChain(llm=llm, \n",
    "                       prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Analyze the sentiment of the following summary and output it in any of these: (positive, negative, neutral):\\n\\nSummary: {summary}\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, \n",
    "                      prompt=fourth_prompt, \n",
    "                      output_key=\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains = [chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables = [\"Review\"],\n",
    "    output_variables = [\"English_Review\",\"summary\", \"language\", \"sentiment\"],\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'Review': 'एसर का नया एडवांस आई-सीरीज 43-इंच टीवी देखने में जितना आकर्षक है, इस्तेमाल करने में उतना ही स्मूथ। इसकी पिक्चर क्वालिटी और साउंड दोनों ही शानदार हैं। स्मार्ट फीचर्स के मामले में भी ये टीवी पीछे नहीं है, गूगल असिस्टेंट सपोर्ट के साथ आप आराम से वॉइस कमांड दे सकते हैं। हालांकि, हैंड्स-फ्री फीचर की कमी थोड़ी खलती है। इसके अलावा, टीवी के साथ दिया गया रिमोट भी काफी अच्छा है, सभी जरूरी बटन और OTT प्लेटफॉर्म के लिए डेडिकेटेड बटन भी मौजूद हैं। कुल मिलाकर, अगर आप एक अच्छा और किफायती स्मार्ट टीवी ढूंढ रहे हैं तो एसर का ये टीवी आपके लिए एक बढ़िया विकल्प हो सकता है।', 'English_Review': \"Here is the translation of the review to English:\\n\\nAsus's new Advance i-Series 43-inch TV is as attractive to watch as it is to use. Its picture quality and sound are both excellent. In terms of smart features, this TV is not behind either, with Google Assistant support, you can easily give voice commands. However, the lack of a hands-free feature is a bit annoying. Additionally, the remote control provided with the TV is also quite good, with all necessary buttons and dedicated buttons for OTT platforms. Overall, if you are looking for a good and affordable smart TV, this Asus TV could be a great option for you.\", 'summary': 'Here is a summary of the review in 1 sentence:\\n\\nThe Asus Advance i-Series 43-inch TV offers excellent picture and sound quality, smart features like Google Assistant, and a good remote control, making it a great and affordable option for those looking for a smart TV.', 'language': 'हिंदी', 'sentiment': 'The sentiment of the summary is: **Positive**\\n\\nThe summary uses words like \"excellent\", \"great\", and \"affordable\" to describe the TV, indicating a very positive opinion.'}\n"
     ]
    }
   ],
   "source": [
    "# Run the SequentialChain\n",
    "review = 'एसर का नया एडवांस आई-सीरीज 43-इंच टीवी देखने में जितना आकर्षक है, इस्तेमाल करने में उतना ही स्मूथ। इसकी पिक्चर क्वालिटी और साउंड दोनों ही शानदार हैं। स्मार्ट फीचर्स के मामले में भी ये टीवी पीछे नहीं है, गूगल असिस्टेंट सपोर्ट के साथ आप आराम से वॉइस कमांड दे सकते हैं। हालांकि, हैंड्स-फ्री फीचर की कमी थोड़ी खलती है। इसके अलावा, टीवी के साथ दिया गया रिमोट भी काफी अच्छा है, सभी जरूरी बटन और OTT प्लेटफॉर्म के लिए डेडिकेटेड बटन भी मौजूद हैं। कुल मिलाकर, अगर आप एक अच्छा और किफायती स्मार्ट टीवी ढूंढ रहे हैं तो एसर का ये टीवी आपके लिए एक बढ़िया विकल्प हो सकता है।'\n",
    "result = overall_chain({\"Review\": review})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_feedback_template = \"\"\"You are an empathetic customer service representative.\n",
    "Summarize the following positive feedback and generate a thank-you response.\n",
    "Here is the feedback:\n",
    "{input}\"\"\"\n",
    "\n",
    "negative_feedback_template = \"\"\"You are an empathetic customer service representative.\n",
    "Summarize the following negative feedback and generate an apology response with a follow-up question for more details.\n",
    "Here is the feedback:\n",
    "{input}\"\"\"\n",
    "\n",
    "neutral_feedback_template = \"\"\"You are an empathetic customer service representative.\n",
    "Summarize the following neutral feedback and generate a generic response.\n",
    "Here is the feedback:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"positive\",\n",
    "        \"description\": \"Good for processing positive feedback\",\n",
    "        \"prompt_template\": positive_feedback_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"negative\",\n",
    "        \"description\": \"Good for processing negative feedback\",\n",
    "        \"prompt_template\": negative_feedback_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"neutral\",\n",
    "        \"description\": \"Good for processing neutral feedback\",\n",
    "        \"prompt_template\": neutral_feedback_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='You are an empathetic customer service representative.\\nSummarize the following positive feedback and generate a thank-you response.\\nHere is the feedback:\\n{input}'))]), llm=ChatTogether(client=<openai.resources.chat.completions.Completions object at 0x76b62836cb80>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x76b61037d8a0>, model_name='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', temperature=0.2, openai_api_key=SecretStr('**********'), max_tokens=200, together_api_key=SecretStr('**********'))),\n",
       " 'negative': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='You are an empathetic customer service representative.\\nSummarize the following negative feedback and generate an apology response with a follow-up question for more details.\\nHere is the feedback:\\n{input}'))]), llm=ChatTogether(client=<openai.resources.chat.completions.Completions object at 0x76b62836cb80>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x76b61037d8a0>, model_name='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', temperature=0.2, openai_api_key=SecretStr('**********'), max_tokens=200, together_api_key=SecretStr('**********'))),\n",
       " 'neutral': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='You are an empathetic customer service representative.\\nSummarize the following neutral feedback and generate a generic response.\\nHere is the feedback:\\n{input}'))]), llm=ChatTogether(client=<openai.resources.chat.completions.Completions object at 0x76b62836cb80>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x76b61037d8a0>, model_name='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', temperature=0.2, openai_api_key=SecretStr('**********'), max_tokens=200, together_api_key=SecretStr('**********')))}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Destination Chains Setup: A loop iterates over each item in prompt_infos,\n",
    "# creates a chain for each feedback type,\n",
    "# and stores it in the destination_chains dictionary.\n",
    "# Each chain is created by combining the ChatPromptTemplate with LLMChain.\n",
    "\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain # this is what we'll pass to the router chain\n",
    "\n",
    "destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['positive: Good for processing positive feedback',\n",
       "  'negative: Good for processing negative feedback',\n",
       "  'neutral: Good for processing neutral feedback'],\n",
       " 'positive: Good for processing positive feedback\\nnegative: Good for processing negative feedback\\nneutral: Good for processing neutral feedback')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos] # this is what we'll pass to the template\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "\n",
    "destinations, destinations_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "default_prompt = ChatPromptTemplate.from_template(\"reply to this {input} gracefully\")\n",
    "\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n",
    "# This chain acts as a fallback when the router is unable to categorize the input. It generates a generic response.\n",
    "\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\"\n",
    "\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "template=router_template,\n",
    "input_variables=[\"input\"],\n",
    "output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "                         destination_chains=destination_chains,\n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "positive: {'input': 'I love the new update! The app is much faster and the design looks great.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here\\'s a summary of the feedback and a thank-you response:\\n\\n**Summary:** The customer is extremely satisfied with the new update to the app, praising its improved speed and design.\\n\\n**Thank-you response:**\\n\\n\"Thank you so much for your kind words about our latest app update! We\\'re thrilled to hear that you\\'re enjoying the improved speed and design. Our team worked hard to bring you this update, and it\\'s wonderful to know that it\\'s making a positive impact on your experience. We\\'re grateful for customers like you who take the time to share their feedback with us. If you have any other questions or need assistance with anything else, please don\\'t hesitate to reach out. Thank you again for your support!\"'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"I love the new update! The app is much faster and the design looks great.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatTogether(\n",
    "    api_key=os.getenv(\"TOGETHER_API_KEY\"),\n",
    "    temperature= 0.2,\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The top challenge for the Indian government is a multifaceted issue, and I'd be happy to provide some insights. According to various reports and studies, one of the most pressing challenges facing the Indian government is the issue of poverty and income inequality. As of 2022, approximately 220 million people in India live below the poverty line, which is roughly 17% of the country's population. This is despite India's rapid economic growth over the past few decades.\\n\\nAnother significant challenge is the issue of corruption, which is a major obstacle to good governance and economic development. The Indian government has implemented various initiatives to combat corruption, such as the Goods and Services Tax (GST) and the Jan Dhan Yojana scheme, which aims to provide financial inclusion to the poor.\\n\\nAdditionally, the Indian government is also grappling with the issue of climate change, which poses a significant threat to the country's agricultural sector, which is a major contributor to the country's GDP. Rising temperatures and changing precipitation\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Top challenge for Indian Government.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on my analysis, the top 2 challenges for the Indian government are:\\n\\n1. **Poverty and income inequality**: Approximately 220 million people in India live below the poverty line, which is roughly 17% of the country's population.\\n2. **Corruption**: A major obstacle to good governance and economic development, with various initiatives implemented to combat it, such as the Goods and Services Tax (GST) and the Jan Dhan Yojana scheme.\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Give me just top 2 and keep them consize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A question that gets to the heart of the matter! Based on my analysis of various studies and reports, I'd like to propose some potential solutions to address the top 2 challenges facing the Indian government:\n",
      "\n",
      "**Poverty and income inequality**:\n",
      "\n",
      "1. **Targeted social welfare programs**: Implementing programs that provide direct financial assistance to the most vulnerable populations, such as the elderly, disabled, and those living in extreme poverty.\n",
      "2. **Education and skill development**: Investing in education and vocational training to equip people with skills that are in demand in the job market, thereby increasing their employability and earning potential.\n",
      "\n",
      "**Corruption**:\n",
      "\n",
      "1. **Strengthening institutions**: Ensuring that institutions such as the judiciary, police, and anti-corruption agencies are independent, effective, and free from corruption.\n",
      "2. **Digitalization and transparency**: Implementing digital platforms and tools to increase transparency and accountability in government transactions, such as e-procurement and e-governance systems.\n",
      "\n",
      "These\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"What you think could be the solution to this ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Top challenge for Indian Government.\n",
      "AI: The top challenge for the Indian government is a multifaceted issue, and I'd be happy to provide some insights. According to various reports and studies, one of the most pressing challenges facing the Indian government is the issue of poverty and income inequality. As of 2022, approximately 220 million people in India live below the poverty line, which is roughly 17% of the country's population. This is despite India's rapid economic growth over the past few decades.\n",
      "\n",
      "Another significant challenge is the issue of corruption, which is a major obstacle to good governance and economic development. The Indian government has implemented various initiatives to combat corruption, such as the Goods and Services Tax (GST) and the Jan Dhan Yojana scheme, which aims to provide financial inclusion to the poor.\n",
      "\n",
      "Additionally, the Indian government is also grappling with the issue of climate change, which poses a significant threat to the country's agricultural sector, which is a major contributor to the country's GDP. Rising temperatures and changing precipitation\n",
      "Human: Give me just top 2 and keep them consize\n",
      "AI: Based on my analysis, the top 2 challenges for the Indian government are:\n",
      "\n",
      "1. **Poverty and income inequality**: Approximately 220 million people in India live below the poverty line, which is roughly 17% of the country's population.\n",
      "2. **Corruption**: A major obstacle to good governance and economic development, with various initiatives implemented to combat it, such as the Goods and Services Tax (GST) and the Jan Dhan Yojana scheme.\n",
      "Human: What you think could be the solution to this ?\n",
      "AI: A question that gets to the heart of the matter! Based on my analysis of various studies and reports, I'd like to propose some potential solutions to address the top 2 challenges facing the Indian government:\n",
      "\n",
      "**Poverty and income inequality**:\n",
      "\n",
      "1. **Targeted social welfare programs**: Implementing programs that provide direct financial assistance to the most vulnerable populations, such as the elderly, disabled, and those living in extreme poverty.\n",
      "2. **Education and skill development**: Investing in education and vocational training to equip people with skills that are in demand in the job market, thereby increasing their employability and earning potential.\n",
      "\n",
      "**Corruption**:\n",
      "\n",
      "1. **Strengthening institutions**: Ensuring that institutions such as the judiciary, police, and anti-corruption agencies are independent, effective, and free from corruption.\n",
      "2. **Digitalization and transparency**: Implementing digital platforms and tools to increase transparency and accountability in government transactions, such as e-procurement and e-governance systems.\n",
      "\n",
      "These\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Top challenge for Indian Government.\\nAI: The top challenge for the Indian government is a multifaceted issue, and I'd be happy to provide some insights. According to various reports and studies, one of the most pressing challenges facing the Indian government is the issue of poverty and income inequality. As of 2022, approximately 220 million people in India live below the poverty line, which is roughly 17% of the country's population. This is despite India's rapid economic growth over the past few decades.\\n\\nAnother significant challenge is the issue of corruption, which is a major obstacle to good governance and economic development. The Indian government has implemented various initiatives to combat corruption, such as the Goods and Services Tax (GST) and the Jan Dhan Yojana scheme, which aims to provide financial inclusion to the poor.\\n\\nAdditionally, the Indian government is also grappling with the issue of climate change, which poses a significant threat to the country's agricultural sector, which is a major contributor to the country's GDP. Rising temperatures and changing precipitation\\nHuman: Give me just top 2 and keep them consize\\nAI: Based on my analysis, the top 2 challenges for the Indian government are:\\n\\n1. **Poverty and income inequality**: Approximately 220 million people in India live below the poverty line, which is roughly 17% of the country's population.\\n2. **Corruption**: A major obstacle to good governance and economic development, with various initiatives implemented to combat it, such as the Goods and Services Tax (GST) and the Jan Dhan Yojana scheme.\\nHuman: What you think could be the solution to this ?\\nAI: A question that gets to the heart of the matter! Based on my analysis of various studies and reports, I'd like to propose some potential solutions to address the top 2 challenges facing the Indian government:\\n\\n**Poverty and income inequality**:\\n\\n1. **Targeted social welfare programs**: Implementing programs that provide direct financial assistance to the most vulnerable populations, such as the elderly, disabled, and those living in extreme poverty.\\n2. **Education and skill development**: Investing in education and vocational training to equip people with skills that are in demand in the job market, thereby increasing their employability and earning potential.\\n\\n**Corruption**:\\n\\n1. **Strengthening institutions**: Ensuring that institutions such as the judiciary, police, and anti-corruption agencies are independent, effective, and free from corruption.\\n2. **Digitalization and transparency**: Implementing digital platforms and tools to increase transparency and accountability in government transactions, such as e-procurement and e-governance systems.\\n\\nThese\"}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coversation Buffer Window Memory\n",
    "\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "\n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: i am fine, that you. how are you Suraaj\\nHuman: working on understanding langchian\\nAI: i can help you in understanding langchain'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversation Token Based Buffer Memory\n",
    "# ! pip install tiktoken\n",
    "\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "# llm = ChatTogether(\n",
    "#     api_key=os.getenv(\"TOGETHER_API_KEY\"),\n",
    "#     temperature= 0.2,\n",
    "#     model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "#     max_tokens=200\n",
    "# )\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = \"2023-03-15-preview\",\n",
    "    temperature = 0.2, \n",
    "    model = \"gpt-4o-mini\"\n",
    "    )\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm=llm, \n",
    "                                       max_token_limit=50)\n",
    "\n",
    "memory.save_context({\"input\": \"Hello i am Suraaj\"},\n",
    "                    {\"output\": \"i am an ai assistant\"})\n",
    "\n",
    "memory.save_context({\"input\": \"how are you ai assistant\"},\n",
    "                    {\"output\": \"i am fine, that you. how are you Suraaj\"})\n",
    "\n",
    "memory.save_context({\"input\": \"working on understanding langchian\"},\n",
    "                    {\"output\": \"i can help you in understanding langchain\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation Summary Memory\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# we have created a long string with lots of information\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, \n",
    "                                         max_token_limit=100)\n",
    "\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"},\n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human greets the AI, and they exchange casual pleasantries. The human then asks about the day's schedule.\n",
      "AI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
