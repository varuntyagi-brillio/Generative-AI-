{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRCPtnaEdLZF",
        "outputId": "ee7f7163-369a-4e4f-a352-de3558a4f587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openAI\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openAI) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openAI) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openAI)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openAI) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openAI) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openAI) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openAI) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openAI) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openAI) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openAI) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openAI)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openAI)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openAI) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openAI) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openAI\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openAI-1.30.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "0sLpyjnLefeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# openai.api_key = \"hadjkshfkjdafk jdhfkjadhfkjadhkf\"\n"
      ],
      "metadata": {
        "id": "V6JWzmbxfG_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won IPL 2020\"}\n",
        "    ]"
      ],
      "metadata": {
        "id": "rx2FLd2Xffl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GumDdCGfgNh",
        "outputId": "6616423a-8b2c-467a-bd8e-4ed655249d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
              " {'role': 'user', 'content': 'Who won IPL 2020'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-16k\",\n",
        "  messages=messages\n",
        ")"
      ],
      "metadata": {
        "id": "W2bSzEVigMRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIsmrIxIgjsy",
        "outputId": "3e3a0bb8-61dc-4285-8102-7f73f6436e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9TA311EadXiUYiG0LfDBYXMICjdAk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Mumbai Indians (MI) won the Indian Premier League (IPL) 2020.', role='assistant', function_call=None, tool_calls=None))], created=1716737163, model='gpt-3.5-turbo-16k-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=23, total_tokens=42))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response.choices[0].message.content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B80Q6c8Agmd6",
        "outputId": "326d06dc-e96c-4962-b035-ad51676ae01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mumbai Indians (MI) won the Indian Premier League (IPL) 2020.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\"role\": \"user\", \"content\": \"You are a very helpfull assistant. Who won IPL 2020\"}\n",
        "    ]"
      ],
      "metadata": {
        "id": "ibEO51zag73s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''You are a helpful Neural Network teaching assistant.\n",
        "Explain the various optimisation methods in Neural network.\n",
        "Provide an exhaustive summary of the methods describing what they do,\n",
        "sample code for each, and guidelines on when to use which method.\n",
        "'''\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n"
      ],
      "metadata": {
        "id": "_3N8l3XQh0OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-16k\",\n",
        "    messages=message,\n",
        "    max_tokens=800,\n",
        "    temperature=0.5,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0)\n",
        "\n",
        "print(chat_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE-hQ0QEiXDU",
        "outputId": "e13d32e2-d986-446c-9095-afd891c25ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are several optimization methods commonly used in neural networks to improve the training process and find optimal values for the model's parameters. Some of the popular optimization methods are:\n",
            "\n",
            "1. Gradient Descent (GD):\n",
            "   - Description: GD is a basic optimization method that updates the model's parameters in the opposite direction of the gradient of the loss function with respect to the parameters.\n",
            "   - Code:\n",
            "     ```python\n",
            "     learning_rate = 0.01\n",
            "     for param in model.parameters():\n",
            "         param -= learning_rate * param.grad\n",
            "     ```\n",
            "   - Guidelines: GD is suitable for small datasets or shallow networks. It can be slow for large datasets or deep networks as it requires computing gradients for the entire dataset.\n",
            "\n",
            "2. Stochastic Gradient Descent (SGD):\n",
            "   - Description: SGD is an optimization method that updates the model's parameters based on the gradient of the loss function computed on a randomly selected subset (mini-batch) of the training data.\n",
            "   - Code:\n",
            "     ```python\n",
            "     learning_rate = 0.01\n",
            "     for epoch in range(num_epochs):\n",
            "         for inputs, labels in dataloader:\n",
            "             optimizer.zero_grad()\n",
            "             outputs = model(inputs)\n",
            "             loss = criterion(outputs, labels)\n",
            "             loss.backward()\n",
            "             optimizer.step()\n",
            "     ```\n",
            "   - Guidelines: SGD is suitable for large datasets as it uses mini-batches, which reduces memory requirements. It can converge faster than GD but may have high variance due to the random sampling of mini-batches.\n",
            "\n",
            "3. Mini-Batch Gradient Descent:\n",
            "   - Description: Mini-Batch GD is a variation of SGD that updates the model's parameters based on the gradient computed on a small randomly selected subset (mini-batch) of the training data.\n",
            "   - Code:\n",
            "     ```python\n",
            "     learning_rate = 0.01\n",
            "     for epoch in range(num_epochs):\n",
            "         for i in range(0, num_samples, batch_size):\n",
            "             optimizer.zero_grad()\n",
            "             inputs = data[i:i+batch_size]\n",
            "             labels = targets[i:i+batch_size]\n",
            "             outputs = model(inputs)\n",
            "             loss = criterion(outputs, labels)\n",
            "             loss.backward()\n",
            "             optimizer.step()\n",
            "     ```\n",
            "   - Guidelines: Mini-Batch GD offers a balance between GD and SGD. It reduces the variance of SGD while still being memory-efficient. It is commonly used in practice.\n",
            "\n",
            "4. Adam (Adaptive Moment Estimation):\n",
            "   - Description: Adam is an adaptive optimization algorithm that uses both the first-order moment (mean) and the second-order moment (uncentered variance) of the gradients to update the model's parameters.\n",
            "   - Code:\n",
            "     ```python\n",
            "     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
            "     for epoch in range(num_epochs):\n",
            "         optimizer.zero_grad()\n",
            "         outputs = model(inputs)\n",
            "         loss = criterion(outputs, labels)\n",
            "         loss.backward()\n",
            "         optimizer.step()\n",
            "     ```\n",
            "   - Guidelines: Adam is a popular choice due to its adaptive learning rate and momentum. It works well in most cases and often converges faster than other methods.\n",
            "\n",
            "5. RMSprop (Root Mean Square Propagation):\n",
            "   - Description: RMSprop is an optimization method that uses an exponentially weighted moving average of squared gradients to update the model's parameters. It divides the learning rate by a running average of the recent gradient magnitudes.\n",
            "   - Code:\n",
            "     ```python\n",
            "     optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
            "     for epoch in range(num_epochs):\n",
            "         optimizer.zero_grad()\n",
            "         outputs = model(inputs)\n",
            "         loss = criterion(outputs, labels)\n",
            "         loss.backward()\n",
            "         optimizer.step()\n",
            "     ```\n",
            "   - Guidelines: RMSprop is effective in dealing with the vanishing/exploding gradient problem. It is suitable for recurrent neural networks (RNNs) and can converge faster than basic GD.\n",
            "\n",
            "The choice of optimization method depends on various factors such as the dataset size, network architecture, and specific problem. Generally, Adam and RMSprop are preferred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-16k\",\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON to the key 'answer'.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won IPL 2020\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "fHbwPnZ3icWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chat_response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "KfyIkuzLk0ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErN1VCO3k21i",
        "outputId": "bbd4f029-5705-4c73-b483-2d9e8eb96014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"answer\": \"Mumbai Indians won IPL 2020.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json_output = json.loads(output)\n",
        "\n",
        "result = json_output.get('answer', \"None\")\n",
        "\n",
        "# The 'result' variable now contains the value associated with the 'answer' key or \"None\" if the key is not present.\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm4NGveuk4Ux",
        "outputId": "2c8bee4f-007f-4235-f11f-008f0ead25dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mumbai Indians won IPL 2020.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZAKjhutlBRS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}