{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gdown 1yVbhJWh4L1unDbDT4APOusTXlwic7aE9\n",
    "# ! gdown 1-F1DO6UNkz3ndjSV4kSzu7zcaQJtf5De\n",
    "# ! gdown 1LouWfzlgol2J2EdqFy0YVIPh93uSq2ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv # python -m pip install python-dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader \n",
    "# pip install --upgrade langchain\n",
    "# pip install -U langchain-community\n",
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"2022_Annual_Report.pdf\"),\n",
    "    # PyPDFLoader(\"SQL Revision Notes.pdf\"),\n",
    "    PyPDFLoader(\"2022_Annual_Report.pdf\"),\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/Documents/MS/GenAI/venv_gen/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Embeddings\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "# pip install -U sentence-transformers\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embedding = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# embedding = AzureOpenAIEmbeddings(\n",
    "#     api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "#     azure_endpoint=os.getenv(\"AZURE_BASE_URL\"),\n",
    "#     api_version = \"2023-03-15-preview\",\n",
    "#     model=\"text-embedding-3-small\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS # pip install faiss-cpu\n",
    "\n",
    "db = FAISS.from_documents(\n",
    "    splits,\n",
    "    embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is discussed about metrics \"\n",
    "docs = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr = db.max_marginal_relevance_search(query, k=4)\n",
    "docs_mmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"PA - Consolidated lecture notes.pdf\"),\n",
    "    PyPDFLoader(\"SQL Revision Notes.pdf\"),\n",
    "    PyPDFLoader(\"2022_Annual_Report.pdf\")\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "split_texts = [str(doc.page_content) for doc in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import create_langchain_embedding\n",
    "\n",
    "ef = create_langchain_embedding(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "client = chromadb.PersistentClient(path=\"database\")\n",
    "\n",
    "chroma_collection = chroma_client.create_collection(\"chroma_check_1\", embedding_function=ef)\n",
    "# This method creates a new collection within ChromaDB.\n",
    "# Any document added to this collection will be processed using the ef function to generate its embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [str(i) for i in range(len(split_texts))] #creating ids for all splits\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=split_texts)\n",
    "chroma_collection.count() # verify that all the documents were added successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA  \n",
      "INCOME STATEMENTS  \n",
      "  \n",
      "(In millions, except per share amounts)          \n",
      "        \n",
      "Year Ended June  30, 2022  2021  2020  \n",
      "        \n",
      "Revenue:        \n",
      "Product  $    72,732   $    71,074   $    68,041   \n",
      "Service and other   125,538    97,014    74,974         \n",
      "Total revenue   198,270    168,088    143,015         \n",
      "Cost of revenue:        \n",
      "Product   19,064    18,219    16,017   \n",
      "Service and other   43,586    34,013    30,061         \n",
      "Total cost of revenue   62,650    52,232    46,078         \n",
      "Gross margin   135,620    115,856    96,937   \n",
      "Research and development   24,512    20,716    19,269   \n",
      "Sales and marketing   21,825    20,117    19,598   \n",
      "General and administrative   5,900    5,107    5,111         \n",
      "Operating income   83,383    69,916    52,959   \n",
      "Other income, net   333   1,186    77        \n",
      "Income before income taxes   83,716    71,102    53,036   \n",
      "Provision for income taxes   10,978    9,831    8,755         \n",
      "Net income  $ 72,738   $ 61,271   $ 44,281           \n",
      "        \n",
      "Earnings per share:        \n",
      "Basic  $ 9.70  $ 8.12  $ 5.82  \n",
      "Diluted  $ 9.65  $ 8.05  $ 5.76  \n",
      "        \n",
      "Weighted average shares outstanding:        \n",
      "Basic   7,496    7,547    7,610   \n",
      "Diluted   7,540    7,608    7,683     \n",
      "Refer to accompanying notes.\n",
      "\n",
      "\n",
      "• We evaluated the reasonableness of management’s estimate of stand -alone selling prices for products and services \n",
      "that are not sold separately.  \n",
      "• We tested the mathematical accuracy of management’s calculations of revenue and the associated timing of revenue \n",
      "recognized in the financial statements.\n",
      "\n",
      "\n",
      "82   \n",
      "In addition, certain costs incurred at a corporate level that are identifiable and that benefit our segments are allocated to  \n",
      "them. These allocated costs inc lude legal, including settlements and fines, information technology, human resources, \n",
      "finance, excise taxes, field selling, shared facilities services, and customer service and support. Each allocation is \n",
      "measured differently based on the specific facts an d circumstances of the costs being allocated.  \n",
      "Segment revenue and operating income were as follows during the periods presented:  \n",
      "  \n",
      "(In millions)          \n",
      "        \n",
      "Year Ended June  30, 2022  2021  2020  \n",
      "        \n",
      "Revenue        \n",
      "        \n",
      "Productivity and Business Processes  $ 63,364   $ 53,915   $ 46,398   \n",
      "Intelligent Cloud   75,251    60,080    48,366   \n",
      "More Personal Computing   59,655    54,093    48,251         \n",
      "Total  $  198,270   $    168,088   $    143,015           \n",
      "  \n",
      "Operating Income  \n",
      "        \n",
      "Productivity and Business Processes  $ 29,687   $ 24,351   $ 18,724   \n",
      "Intelligent Cloud   32,721    26,126    18,324   \n",
      "More Personal Computing   20,975    19,439    15,911         \n",
      "Total  $ 83,383   $ 69,916   $ 52,959           \n",
      "No sales to an individual customer or country other than the United States accounted for more than 10% of revenue for \n",
      "fiscal years 2022, 2021, or 2020. Revenue, classified by the major geographic areas in which our customers were located, \n",
      "was as follows:  \n",
      "  \n",
      "(In millions)\n",
      "\n",
      "\n",
      "was as follows:  \n",
      "  \n",
      "(In millions)          \n",
      "        \n",
      "Year Ended June  30, 2022  2021  2020  \n",
      "        \n",
      "United States (a) $ 100,218   $ 83,953   $ 73,160   \n",
      "Other countries   98,052    84,135    69,855         \n",
      "Total  $ 198,270   $ 168,088   $ 143,015           \n",
      "(a) Includes billings to OEMs and certain multinational organizations because of the nature of these businesses and the \n",
      "impracticability of determining the geographic source of the revenue.  \n",
      "Revenue, classified by significant product and service offerings, was  as follows:  \n",
      "  \n",
      "(In millions)          \n",
      "        \n",
      "Year Ended June  30, 2022  2021  2020  \n",
      "        \n",
      "Server products and cloud services  $ 67,321   $ 52,589   $ 41,379   \n",
      "Office products and cloud services   44,862    39,872    35,316   \n",
      "Windows   24,761    22,488    21,510   \n",
      "Gaming   16,230    15,370    11,575   \n",
      "LinkedIn   13,816    10,289    8,077   \n",
      "Search and news advertising   11,591    9,267    8,524   \n",
      "Enterprise Services   7,407    6,943    6,409   \n",
      "Devices   6,991    6,791    6,457   \n",
      "Other   5,291    4,479    3,768         \n",
      "Total  $   198,270   $  168,088   $   143,015           \n",
      "We have recast certain previously reported amounts in the table above to conform to the way we internally manage and \n",
      "monitor our business.\n",
      "\n",
      "\n",
      "Long -term income taxes   26,069    27,190   \n",
      "Long -term unearned revenue   2,870    2,616   \n",
      "Deferred income taxes   230   198  \n",
      "Operating lease liabilities   11,489    9,629   \n",
      "Other long -term liabilities   15,526    13,427       \n",
      "Total liabilities   198,298    191,791       \n",
      "Commitments and contingencies      \n",
      "Stockholders’ equity:      \n",
      "Common stock and paid -in capital – shares authorized 24,000; outstanding  7,464 and 7,519   86,939    83,111   \n",
      "Retained earnings   84,281    57,055   \n",
      "Accumulated other comprehensive income (loss)   (4,678 )  1,822       \n",
      "Total stockholders’ equity   166,542    141,988       \n",
      "Total liabilities and stockholders’ equity  $ 364,840   $ 333,779         \n",
      "Refer to accompanying notes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print((document))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using open source llama 3 model from TogetherAI \n",
    "\n",
    "from langchain_together import ChatTogether\n",
    "\n",
    "llm = ChatTogether(\n",
    "    api_key = os.getenv(\"TOGETHER_API_KEY\"),\n",
    "    temperature=0.0, \n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, retrieved_documents, llm=llm):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    content = response.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total revenue for the year ended June 30, 2022 was $198,270 million.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "\n",
    "print((output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "4   \n",
      "Our commitment to responsibly develop and use technologies like AI is core to who we are. We put our commitment into \n",
      "practice, not only within Microsoft but by empowering our custom ers and partners to do the same and by advocating for \n",
      "policy change. We released our Responsible AI Standard, which outlines 17 goals aligned to our six AI principles and \n",
      "includes tools and practices to support them. And we share our open -source tools, inc luding the new Responsible AI \n",
      "Dashboard, to help developers building AI technologies identify and mitigate issues before deployment.  \n",
      "Finally, we provide clear reporting and information on how we run our business and how we work with customers and \n",
      "partners , delivering the transparency that is central to trust. Our annual Impact Summary shares more about our progress \n",
      "and learnings across these four commitments, and our Reports Hub  provides detailed reports on our environmental data, \n",
      "our political activities,  our workforce demographics, our human rights work, and more.  \n",
      "We should all be proud of this work —and I am. But it’s easy to talk about what we’re doing well. As we look to the next \n",
      "year and beyond, we’ll continue to reflect on where the world needs us to do better.  \n",
      "OUR OPPORTUNITY  \n",
      "Now, let me turn to how we are positioned to capture the massive opportunities ahead. Over the past few years, I’ve \n",
      "written extensively about digital transformation, but now we need to go beyond that to deliver on what I call t he “digital\n",
      "\n",
      "SQL\n",
      "Revision\n",
      "notes\n",
      "\n",
      "response to the war in Ukraine, including support for government, busin esses, nonprofits, and humanitarian assistance for \n",
      "refugees. And, through our AI for Humanitarian Action initiative, we’re helping organizations harness the power of AI to \n",
      "improve their disaster preparedness, response, and recovery.  \n",
      "Finally, we continued working toward our five -year commitment to bridge the disability divide for the more than 1  billion \n",
      "people around the world with disabilities, seeking to expand accessibility in technology, the workforce, and\n",
      "\n",
      "cities\n",
      "have\n",
      "started\n",
      "to\n",
      "reopen.\n",
      "In\n",
      "which\n",
      "case,\n",
      "the\n",
      "rising\n",
      "interest\n",
      "in\n",
      "events\n",
      "may\n",
      "only\n",
      "be\n",
      "concentrated\n",
      "in\n",
      "those\n",
      "cities\n",
      "that\n",
      "are\n",
      "not\n",
      "re-opened\n",
      "○\n",
      "O\n",
      "-\n",
      "Other\n",
      "related\n",
      "features\n",
      "affected:\n",
      "■\n",
      "If\n",
      "an\n",
      "interest\n",
      "in\n",
      "events\n",
      "is\n",
      "going\n",
      "up,\n",
      "do\n",
      "we\n",
      "see\n",
      "a\n",
      "similar\n",
      "jump\n",
      "in\n",
      "Instagram\n",
      "or\n",
      "Facebook\n",
      "stories\n",
      "because\n",
      "users\n",
      "attending\n",
      "these\n",
      "events\n",
      "will\n",
      "have\n",
      "more\n",
      "content\n",
      "to\n",
      "post\n",
      "about?\n",
      "○\n",
      "P\n",
      "-\n",
      "Platform:\n",
      "■\n",
      "Are\n",
      "we\n",
      "seeing\n",
      "this\n",
      "increase\n",
      "across\n",
      "both\n",
      "Android\n",
      "/\n",
      "iOS?\n",
      "■\n",
      "Across\n",
      "Mobile\n",
      "/\n",
      "Desktop?\n",
      "■\n",
      "Across\n",
      "Mac\n",
      "/\n",
      "Windows?\n",
      "■\n",
      "If\n",
      "only\n",
      "one\n",
      "of\n",
      "them\n",
      "is\n",
      "seeing\n",
      "an\n",
      "increase,\n",
      "we\n",
      "should\n",
      "explore\n",
      "if\n",
      "there’s\n",
      "an\n",
      "engineering\n",
      "bug\n",
      "with\n",
      "the\n",
      "platform\n",
      "that\n",
      "has\n",
      "caused\n",
      "a\n",
      "glitch\n",
      "○\n",
      "C\n",
      "-\n",
      "Cannibalization:\n",
      "If\n",
      "the\n",
      "metric\n",
      "for\n",
      "a\n",
      "product\n",
      "is\n",
      "decreasing,\n",
      "is\n",
      "it\n",
      "because\n",
      "another\n",
      "product\n",
      "we\n",
      "offer\n",
      "is\n",
      "cannibalizing\n",
      "engagement?\n",
      "Alternatively,\n",
      "if\n",
      "the\n",
      "metric\n",
      "in\n",
      "question\n",
      "is\n",
      "increasing,\n",
      "are\n",
      "we\n",
      "cannibalizing\n",
      "from\n",
      "our\n",
      "other\n",
      "offerings?\n",
      "■\n",
      "Around\n",
      "the\n",
      "time\n",
      "when\n",
      "the\n",
      "spike\n",
      "in\n",
      "event\n",
      "clicks\n",
      "happened,\n",
      "are\n",
      "we\n",
      "seeing\n",
      "a\n",
      "decrease\n",
      "in\n",
      "#\n",
      "clicks\n",
      "on\n",
      "proﬁles/pages\n",
      "/\n",
      "groups?\n",
      "■\n",
      "Is\n",
      "there\n",
      "a\n",
      "speciﬁc\n",
      "category\n",
      "that\n",
      "we’re\n",
      "cannibalizing\n",
      "from\n",
      "or\n",
      "is\n",
      "it\n",
      "evenly\n",
      "distributed?\n",
      "■\n",
      "For\n",
      "instance,\n",
      "is\n",
      "it\n",
      "only\n",
      "users\n",
      "that\n",
      "previously\n",
      "clicked\n",
      "on\n",
      "Groups\n",
      "(not\n",
      "Pages)\n",
      "that\n",
      "are\n",
      "clicking\n",
      "on\n",
      "Events\n",
      "now?\n",
      "●\n",
      "This\n",
      "may\n",
      "indicate\n",
      "that\n",
      "we\n",
      "made\n",
      "a\n",
      "change\n",
      "to\n",
      "the\n",
      "ranking\n",
      "of\n",
      "Groups\n",
      "in\n",
      "our\n",
      "search\n",
      "results.\n",
      "●\n",
      "Did\n",
      "we\n",
      "down\n",
      "rank\n",
      "it?\n",
      "Or\n",
      "accidentally\n",
      "remove\n",
      "it\n",
      "completely?\n",
      "○\n",
      "S\n",
      "-\n",
      "Segmentation:\n",
      "Slice\n",
      "and\n",
      "dice\n",
      "the\n",
      "data\n",
      "to\n",
      "identify\n",
      "the\n",
      "demographic\n",
      "of\n",
      "\n",
      "solution. We are accelerating adoption of AI innovations from research to products. Our innovation helps every developer \n",
      "be an AI developer, with approachable new tools from Azure Machine Learning Studio for c reating simple machine \n",
      "learning models, to the powerful Azure Machine Learning Workbench for the most advanced AI modeling and data \n",
      "science. From GitHub to Visual Studio, we provide a developer tool chain for everyone, no matter the technical \n",
      "experience, a cross all platforms, whether Azure, Windows, or any other cloud or client platform.  \n",
      "Additionally, we are extending our infrastructure beyond the planet, bringing cloud computing to space. Azure Orbital is a \n",
      "fully managed ground station as a service for fa st downlinking of data.  \n",
      "Create More Personal Computing  \n",
      "We strive to make computing more personal by putting people at the core of the experience, enabling them to interact with \n",
      "technology in more intuitive, engaging, and dynamic ways. Microsoft 365 is em powering people and organizations to be \n",
      "productive and secure as they adapt to more fluid ways of working, learning, and playing. Windows also plays a critical \n",
      "role in fueling our cloud business with Windows 365, a desktop operating system that’s also a cl oud service. From another \n",
      "internet -connected device, including Android or macOS devices, you can run Windows 365, just like a virtual machine.\n",
      "\n",
      "●\n",
      "Offering\n",
      "insights\n",
      "into\n",
      "user\n",
      "behavior\n",
      "in\n",
      "the\n",
      "app,\n",
      "such\n",
      "as\n",
      "users\n",
      "spending\n",
      "time\n",
      "on\n",
      "help\n",
      "center\n",
      "articles.\n",
      "●\n",
      "Proposing\n",
      "the\n",
      "setup\n",
      "of\n",
      "A/B\n",
      "testing\n",
      "to\n",
      "compare\n",
      "user\n",
      "behavior\n",
      "and\n",
      "satisfaction\n",
      "between\n",
      "users\n",
      "with\n",
      "and\n",
      "without\n",
      "access\n",
      "to\n",
      "the\n",
      "new\n",
      "feature.\n",
      "●\n",
      "Agreeing\n",
      "to\n",
      "work\n",
      "on\n",
      "making\n",
      "data-driven\n",
      "decisions\n",
      "and\n",
      "collecting\n",
      "relevant\n",
      "data.\n",
      "These\n",
      "responsibilities\n",
      "reﬂect\n",
      "the\n",
      "different\n",
      "roles\n",
      "and\n",
      "expertise\n",
      "of\n",
      "the\n",
      "CEO,\n",
      "Product\n",
      "Manager,\n",
      "and\n",
      "Data\n",
      "Scientist\n",
      "in\n",
      "the\n",
      "context\n",
      "of\n",
      "launching\n",
      "a\n",
      "new\n",
      "feature\n",
      "and\n",
      "ensuring\n",
      "its\n",
      "success.______________________________________________________________________________\n",
      "Judgment\n",
      "Criteria\n",
      "&\n",
      "General\n",
      "Framework\n",
      "-\n",
      "Keep\n",
      "this\n",
      "in\n",
      "mind\n",
      "when\n",
      "addressing\n",
      "business\n",
      "acumen\n",
      "questions.\n",
      "●\n",
      "Judgment\n",
      "Criteria\n",
      "for\n",
      "Interviewers\n",
      ":\n",
      "○\n",
      "Structure\n",
      "-\n",
      "Demonstrate\n",
      "a\n",
      "systematic\n",
      "approach\n",
      "○\n",
      "Comprehensiveness\n",
      "-\n",
      "Covers\n",
      "all\n",
      "important\n",
      "aspects\n",
      "○\n",
      "Feasibility\n",
      "-\n",
      "Practical\n",
      "enough\n",
      "that\n",
      "it\n",
      "could\n",
      "be\n",
      "implemented\n",
      "realistically\n",
      "●\n",
      "General\n",
      "Framework\n",
      "to\n",
      "keep\n",
      "in\n",
      "mind\n",
      ":\n",
      "○\n",
      "Clarify\n",
      "○\n",
      "Plan\n",
      "○\n",
      "Conclude\n",
      "\n",
      "Significant Judgments  \n",
      "Our contracts with customers often include promises to transfer multiple products and services to a customer. \n",
      "Determining whether products and services are considered distinct performance obligations that should be\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross-Encoder, Re-Ranking\n",
    "\n",
    "query = \"What all areas are explored for AI\"\n",
    "\n",
    "results = chroma_collection.query(\n",
    "    query_texts=query,\n",
    "    n_results=8,\n",
    "    include=[\"documents\", \"embeddings\"])\n",
    "\n",
    "retrieved_documents = results[\"documents\"][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction \n",
    "from sentence_transformers import CrossEncoder # ! pip install -U sentence-transformers\n",
    "\n",
    "cross_encoder = CrossEncoder(\"BAAI/bge-reranker-v2-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "0.000108078624\n",
      "0.00054811133\n",
      "1.6217e-05\n",
      "0.00055333\n",
      "0.00016040505\n",
      "0.0022564156\n",
      "0.00022766506\n",
      "1.62869e-05\n"
     ]
    }
   ],
   "source": [
    "pairs = [[query, d_i] for d_i in retrieved_documents]\n",
    "scores = cross_encoder.predict(pairs)\n",
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ordering:\n",
      "5\n",
      "3\n",
      "1\n",
      "6\n",
      "4\n",
      "0\n",
      "7\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"New Ordering:\")\n",
    "new_ord=[]\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o)\n",
    "    new_ord.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "information=\"\"\n",
    "i=0\n",
    "for n in new_ord:\n",
    "    print(n)\n",
    "    information = \"\\n\\n\".join(retrieved_documents[n])\n",
    "    i+=1\n",
    "    if(i==4):\n",
    "        break #taking the first 4 out of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert AI research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "\n",
    "response = llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The areas explored for AI include:\n",
      "\n",
      "1. Offering insights into user behavior in the app, such as user spending time on help center articles.\n",
      "2. Proposing the setup of A/B testing to compare user behavior and satisfaction between users with and without access to the new feature.\n",
      "3. Agreeing to work on making data-driven decisions and collecting relevant data.\n",
      "4. Judgment Criteria & General Framework, including:\n",
      "   - Keeping this in mind when addressing business acumens questions.\n",
      "   - Judgment Criteria for interviewers, including:\n",
      "     • Structure - Demonstrate a systematic approach.\n",
      "     • Comprehensive - Covers all important aspects.\n",
      "     • Feasibility - Practical enough that it could be implemented realistically.\n",
      "5. General Framework to keep in mind, including:\n",
      "   - Clarify\n",
      "   - Plan\n",
      "   - Conclude\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Expansion\n",
    "def augment_multiple_query(query, llm=llm):\n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about an annual report. \"\n",
    "                \"Suggest up to four additional related questions to help them find the information they need, for the provided question. \"\n",
    "                \"Suggest only short questions without compound sentences. Suggest a variety of questions that cover different aspects of the topic.\"\n",
    "                \"Make sure they are complete questions, and that they are related to the original question.\"\n",
    "                \"Output one question per line. Do not number the questions.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "\n",
    "    response = llm.invoke(messages).content\n",
    "    response = response.split(\"\\n\")\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the company's AI research and development expenses?\n",
      "Are there any AI-related partnerships or collaborations mentioned?\n",
      "How does the company plan to integrate AI into its products or services?\n",
      "What are the potential risks or challenges associated with the company's AI initiatives?\n"
     ]
    }
   ],
   "source": [
    "# original_query = \"What has been the investment in AI research?\"\n",
    "original_query = \"What all areas are explored for AI\"\n",
    "augmented_queries = augment_multiple_query(original_query)\n",
    "\n",
    "for query in augmented_queries:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [original_query] + augmented_queries\n",
    "\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents = []\n",
    "for query in queries:\n",
    "    results = chroma_collection.query(query_texts=query, n_results=6, include=['documents', 'embeddings'])\n",
    "    retrieved_documents.extend(results['documents'][0])\n",
    "\n",
    "len(retrieved_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "0.004051035\n",
      "0.0006815926\n",
      "0.0022564137\n",
      "0.02120277\n",
      "2.78124e-05\n",
      "0.00054810924\n",
      "1.7655413e-05\n",
      "1.8816341e-05\n",
      "1.6695913e-05\n",
      "0.00014322968\n",
      "4.0857547e-05\n",
      "2.048527e-05\n",
      "2.78124e-05\n",
      "1.7259448e-05\n",
      "1.8152707e-05\n",
      "2.1308628e-05\n",
      "1.900034e-05\n",
      "1.707421e-05\n",
      "0.0005533279\n",
      "0.00054810924\n",
      "1.715824e-05\n",
      "0.0022564137\n",
      "0.0020823614\n",
      "8.428457e-05\n",
      "1.7259448e-05\n",
      "2.78124e-05\n",
      "1.609909e-05\n",
      "1.6921736e-05\n",
      "1.7714308e-05\n",
      "1.7210403e-05\n"
     ]
    }
   ],
   "source": [
    "pairs = [[original_query, d_i] for d_i in retrieved_documents]\n",
    "scores = cross_encoder.predict(pairs)\n",
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ordering:\n",
      "3\n",
      "0\n",
      "21\n",
      "2\n",
      "22\n",
      "1\n",
      "18\n",
      "19\n",
      "5\n",
      "9\n",
      "23\n",
      "10\n",
      "12\n",
      "25\n",
      "4\n",
      "15\n",
      "11\n",
      "16\n",
      "7\n",
      "14\n",
      "28\n",
      "6\n",
      "13\n",
      "24\n",
      "29\n",
      "20\n",
      "17\n",
      "27\n",
      "8\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"New Ordering:\")\n",
    "new_ord=[]\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o)\n",
    "    new_ord.append(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n",
      "21\n",
      "2\n",
      "22\n",
      "1\n",
      "18\n",
      "19\n",
      "5\n",
      "9\n",
      "23\n",
      "10\n",
      "12\n",
      "25\n",
      "4\n",
      "15\n",
      "11\n",
      "16\n",
      "7\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "information=\"\"\n",
    "i=0\n",
    "for n in new_ord:\n",
    "  print(n)\n",
    "  information = \"\\n\\n\".join(retrieved_documents[n])\n",
    "  i+=1\n",
    "  if(i==20):\n",
    "    break #taking the first 4 out of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert AI research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {original_query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "\n",
    "response = llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The areas explored for AI include:\n",
      "\n",
      "1. Technology-based\n",
      "2. Customer-related\n",
      "3. Marketing-related\n",
      "4. Contract-based\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
